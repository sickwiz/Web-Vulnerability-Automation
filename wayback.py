# import requests
# from pprint import pprint
# from bs4 import BeautifulSoup as bsoup
# from urllib.parse import urljoin


# """It returns all the forms from a given url"""


# def waybackMachine(url):
#     newUrl = 'https://web.archive.org/cdx/search/cdx?url=*.' + \
#         url + '/*&output=text&fl=original&collapse=urlkey'
#     soup = bsoup(requests.get(newUrl).content, "html.parser")
#     return soup

import requests
import sys
from sys import __stdout__, stdout
import json
import os
import subprocess


def waybackMachine(host):
    os.system('clear')
    p = './output/wayback'
    try:
        os.mkdir(p)
    except FileExistsError as exc:
        print(exc)

    try:
        subprocess.run('rm -rf output/wayback/results.json',
                       shell=True, stdout=PIPE)
    except:
        pass

    url = 'http://web.archive.org/cdx/search/cdx?url=*.%s/*&output=json&fl=original&collapse=urlkey' % host

    try:
        r = requests.get(url)
        result = r.json()
        # print(r)
        try:
            with open('output/wayback/results.json', 'w+') as f:
                f.write(json.dumps(result[1:]))
                return True
        except:
            return False
    except:
        return False
